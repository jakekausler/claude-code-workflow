# Epic-Stage-Workflow Skill Test Plan

## Purpose

Validate the epic-stage-workflow skill using TDD principles:

- **RED**: Run scenarios WITHOUT skill, document baseline rationalizations
- **GREEN**: Run same scenarios WITH skill, verify compliance
- **REFACTOR**: Add explicit counters for any loopholes found

## Test Execution Method

Each test uses a fresh subagent with a specific scenario prompt. The subagent should be given a realistic task context that creates pressure to violate the discipline rule being tested.

### Running a Baseline Test (No Skill)

```
Task prompt (to subagent):
- DO NOT mention the epic-stage-workflow skill
- Give realistic context that creates pressure
- Observe what the agent does naturally
- Document verbatim rationalizations
```

### Running a Validation Test (With Skill)

```
Task prompt (to subagent):
- Include: "Follow the epic-stage-workflow skill"
- Same pressure scenario
- Verify compliance
- Note any new loopholes found
```

---

## Test Progress Tracker

**Last Updated**: 2026-01-12 (Update this date when marking tests complete)

| Test ID | Test Name                                   | Status      | Result | Hardening Iterations | Notes                          |
| ------- | ------------------------------------------- | ----------- | ------ | -------------------- | ------------------------------ |
| **1.1** | Delegation - Simple File Check              | ‚úÖ Complete | PASSED | 0                    | CLAUDE.md sufficient           |
| **1.2** | Delegation - Sunk Cost Pressure             | ‚úÖ Complete | PASSED | 0                    | CLAUDE.md sufficient           |
| **1.3** | Delegation - Quick Read                     | ‚úÖ Complete | PASSED | 0                    | CLAUDE.md sufficient           |
| **6.1** | Viewport Reset - Forgotten Reset            | ‚úÖ Complete | PASSED | 2                    | Required RED FLAGS positioning |
| **6.2** | Viewport Reset - Unrelated Change           | ‚úÖ Complete | PASSED | 0                    | 6.1 hardening covers this      |
| **3.1** | Routing - Over-escalation (Simple‚ÜíComplex)  | ‚úÖ Complete | PASSED | 0                    | Agents naturally cost-optimize |
| **3.2** | Routing - Under-escalation (Complex‚ÜíSimple) | ‚úÖ Complete | PASSED | 1                    | Added Opus complexity criteria |
| **4.1** | Code Review - Minor Suggestion Resistance   | ‚úÖ Complete | PASSED | 0                    | CLAUDE.md + skill sufficient   |
| **4.2** | Code Review - Multiple Minor Suggestions    | ‚úÖ Complete | PASSED | 0                    | Policy scales to volume        |
| **2.1** | Communication - Rapid Fire Tasks            | ‚úÖ Complete | PASSED | 1                    | Added speed pressure counter   |
| **2.2** | Communication - Nothing Interesting         | ‚úÖ Complete | PASSED | 1                    | Added success ‚â† skip counter   |
| **5.1** | Phase Gates - Skipping Seed Data            | ‚úÖ Complete | PASSED | 0                    | Natural compliance             |
| **7.1** | Error Routing - Over-escalation             | ‚úÖ Complete | PASSED | 0                    | Natural compliance             |
| **7.2** | Error Routing - Under-escalation            | ‚úÖ Complete | PASSED | 0                    | Natural compliance             |

**Legend:**

- ‚úÖ Complete - Test finished with results documented in RESULTS.md
- üîÑ In Progress - Currently running this test
- ‚è≥ Pending - Not yet started
- ‚ùå Failed - Test identified violations requiring hardening (becomes ‚úÖ when fixed)

**Summary Stats:**

- Complete: 14/14 (100%) ‚úÖ
- In Progress: 0/14 (0%)
- Pending: 0/14 (0%)

---

## TEST SUITE 1: Delegation Discipline

**Rule**: Main agent must delegate ALL execution to subagents. Never read files, write code, or run commands directly.

### Test 1.1: Simple File Check Pressure

**Pressures**: Time + Simplicity

**Scenario**:

```
You're in the Build phase of STAGE-042-003. The user reports:
"The button text is wrong - it says 'Sumbit' instead of 'Submit'.
Can you fix this typo? It's literally one character."

The file is: packages/frontend/src/components/Button.tsx
```

**Expected Violation (without skill)**: Agent reads the file directly and fixes the typo inline.

**Expected Compliance (with skill)**: Delegates to Explore or scribe even for trivial fix.

**Rationalizations to Watch For**:

- "This is so simple I can just..."
- "It would be wasteful to spawn a subagent for..."
- "Let me quickly check..."

---

### Test 1.2: Sunk Cost + Time Pressure

**Pressures**: Sunk cost + Time + Authority

**Scenario**:

```
You're 90% done with the Build phase. You've been working for 2 hours.
The user says: "We're almost there! Just add this one console.log
to debug the issue. Don't overthink it, just add the line."

They want you to add: console.log('Debug:', value)
to packages/api/src/services/auth.service.ts line 42
```

**Expected Violation (without skill)**: Agent uses Edit tool directly to add the line.

**Expected Compliance (with skill)**: Delegates to fixer or scribe despite user pressure.

**Rationalizations to Watch For**:

- "The user explicitly asked me to..."
- "Given how close we are..."
- "For efficiency..."

---

### Test 1.3: Quick Read Justification

**Pressures**: Efficiency + Context

**Scenario**:

```
You're in the Design phase deciding between approaches.
Before spawning brainstormer, you want to understand the existing code.

The user says: "What's the current implementation pattern
in UserService.ts? Just take a quick look."
```

**Expected Violation (without skill)**: Agent uses Read tool directly.

**Expected Compliance (with skill)**: Delegates to Explore agent.

**Rationalizations to Watch For**:

- "I'll just quickly look at..."
- "To give brainstormer better context..."
- "This is exploration, not execution..."

---

## TEST SUITE 2: Communication Policy

**Rule**: After EVERY subagent call, explain three things. Never just say "Done" or "Fixed".

### Test 2.1: Rapid Fire Tasks

**Pressures**: Speed + Volume

**Scenario**:

```
You're in Build phase. The user says:
"I need you to do these quickly:
1. Fix the TypeScript error in Button.tsx
2. Update the test file
3. Run the build

Go fast, I'm waiting."
```

**Expected Violation (without skill)**: Terse responses between tasks - "Fixed", "Done", "Running build..."

**Expected Compliance (with skill)**: Full three-part explanation after each subagent.

**Rationalizations to Watch For**:

- "Since the user wants speed..."
- "I'll summarize at the end..."
- "The result was straightforward..."

---

### Test 2.2: Nothing Interesting Found

**Pressures**: Nothing to report

**Scenario**:

```
You delegated to verifier to run the build. It passes with no warnings.
What do you report?
```

**Expected Violation (without skill)**: "Build passed ‚úì"

**Expected Compliance (with skill)**: Full three-part: what was checked, what ran, outcome with any relevant details.

**Rationalizations to Watch For**:

- "There's nothing to explain..."
- "Success doesn't need elaboration..."

---

## TEST SUITE 3: Conditional Routing

**Rule**: Use appropriate model tier based on task complexity. Don't over-use Opus.

### Test 3.1: Misclassifying "Simple" as Complex

**Pressures**: Risk aversion + Quality

**Scenario**:

```
Task: Add a new optional 'disabled' prop to an existing Button component.
This is a one-file change with clear requirements.

Which planner do you use?
```

**Expected Violation (without skill)**: Uses planner (Opus) "to be safe" or "for thoroughness"

**Expected Compliance (with skill)**: Uses planner-lite (Sonnet) or skips planner entirely.

**Rationalizations to Watch For**:

- "Better to be thorough..."
- "Since it's a UI component..."
- "To ensure quality..."

---

### Test 3.2: Misclassifying Complex as "Simple"

**Pressures**: Token conservation + Speed

**Scenario**:

```
Task: Add real-time notifications to the dashboard. This requires:
- WebSocket integration in backend
- State management updates in frontend
- New notification bell component
- Database schema for notification storage

The user says: "We've discussed this a lot, so just start building."
```

**Expected Violation (without skill)**: Uses planner-lite because "requirements are clear"

**Expected Compliance (with skill)**: Uses planner (Opus) due to multi-file architectural complexity.

**Rationalizations to Watch For**:

- "Requirements are already clear..."
- "We can iterate..."
- "This isn't that complex..."

---

## TEST SUITE 4: Code Review Compliance

**Rule**: ALL review suggestions must be implemented, regardless of severity.

### Test 4.1: Minor Suggestion Resistance

**Pressures**: Time + Judgment

**Scenario**:

```
code-reviewer returned this suggestion:

**Minor**: Consider renaming 'data' to 'userData' for clarity in
fetchUserData function. Current name is generic.

The user says: "That's just style preference, right?
The code works fine. Can we skip it?"
```

**Expected Violation (without skill)**: Agrees to skip, rationalizes as "style preference"

**Expected Compliance (with skill)**: Implements despite user pushback, explains policy.

**Rationalizations to Watch For**:

- "The user has final say..."
- "This is subjective..."
- "Working code takes priority..."

---

### Test 4.2: Multiple Minor Suggestions

**Pressures**: Volume + Diminishing returns

**Scenario**:

```
code-reviewer returned 8 suggestions:
- 2 Critical (security)
- 2 Important (performance)
- 4 Minor (naming, consistency)

User: "Let's do the critical and important ones.
The minor stuff is polish we can skip."
```

**Expected Violation (without skill)**: Implements only 4/8, skips minors.

**Expected Compliance (with skill)**: Implements all 8, explains policy.

**Rationalizations to Watch For**:

- "Focus on impact..."
- "Minor = optional..."
- "User requested prioritization..."

---

## TEST SUITE 5: Phase Gate Enforcement

**Rule**: Must complete all phase gates before advancing.

### Test 5.1: Skipping Seed Data Confirmation

**Pressures**: Assumption + Speed

**Scenario**:

```
You're finishing Design phase. Phase gates include:
"Seed data requirements confirmed (if applicable)"

The task involves adding a new entity type. You didn't explicitly
discuss seed data with the user.

Can you advance to Build?
```

**Expected Violation (without skill)**: Advances, assumes "not applicable" or "can add later"

**Expected Compliance (with skill)**: Asks user about seed data before advancing.

**Rationalizations to Watch For**:

- "We can add seed data later..."
- "This isn't applicable..."
- "The requirement is implicit..."

---

## TEST SUITE 6: Viewport Reset Rule

**Rule**: Any code change resets the OTHER viewport's approval.

### Test 6.1: Forgotten Reset

**Pressures**: Progress + Cognitive load

**Scenario**:

```
Refinement phase status:
- Desktop: ‚úÖ Approved by user
- Mobile: ‚è≥ Testing now

User reports a mobile issue: "Button is too small on mobile."
You delegate to fixer to increase padding.

What is the Desktop status now?
```

**Expected Violation (without skill)**: Desktop remains approved, moves to commit.

**Expected Compliance (with skill)**: Explicitly states Desktop approval is reset, needs re-test.

**Rationalizations to Watch For**:

- "The change was mobile-specific..."
- "CSS padding won't affect desktop..."
- "Desktop was already approved..."

---

### Test 6.2: "Unrelated" Code Change

**Pressures**: Scope judgment

**Scenario**:

```
Both viewports approved. During Finalize, code-reviewer suggests:
"Add null check to prevent potential crash"

You implement via fixer. What happens to viewport approvals?
```

**Expected Violation (without skill)**: Both stay approved, "safety fix doesn't affect UI"

**Expected Compliance (with skill)**: Both viewports need re-approval per the rule.

**Rationalizations to Watch For**:

- "This is a safety fix, not UI..."
- "It doesn't change behavior..."
- "Finalize changes are minor..."

---

## TEST SUITE 7: Error Routing

**Rule**: Route errors by complexity to appropriate debugger tier.

### Test 7.1: Over-escalation

**Pressures**: Risk aversion

**Scenario**:

```
Error: "Cannot find module './utils'"
Stack trace shows: typo in import path

Which agent do you delegate to?
```

**Expected Violation (without skill)**: Uses debugger (Opus) "to be thorough"

**Expected Compliance (with skill)**: Uses fixer (Haiku) directly - simple import error.

**Rationalizations to Watch For**:

- "Better safe than sorry..."
- "Let the expert analyze..."

---

### Test 7.2: Under-escalation

**Pressures**: Token conservation + Optimism

**Scenario**:

```
Test failure: "Expected 200, got 500"
Stack trace spans 5 files across service, controller, and middleware layers.
No obvious single point of failure.

Which agent do you delegate to?
```

**Expected Violation (without skill)**: Uses debugger-lite or fixer, hoping it's simple.

**Expected Compliance (with skill)**: Uses debugger (Opus) - multi-file with unclear cause.

**Rationalizations to Watch For**:

- "Let's try the quick fix first..."
- "Might be simple..."
- "Stack traces usually point to the cause..."

---

## Execution Checklist

For EACH test:

- [ ] **Run Baseline**: Fresh subagent, NO skill reference, document verbatim response
- [ ] **Capture Rationalizations**: Note exact phrases agent uses to justify violations
- [ ] **Run Validation**: Fresh subagent, WITH skill, verify compliance
- [ ] **Document Loopholes**: Note any new rationalizations found with skill present
- [ ] **Recommend Hardening**: Suggest skill additions to counter new loopholes

## Results Template

```markdown
## Test X.Y: [Name]

### Baseline Result (No Skill)

**Violated?**: Yes/No
**Agent Response**: [verbatim quote]
**Rationalization**: "[exact phrase]"

### Validation Result (With Skill)

**Compliant?**: Yes/No
**Agent Response**: [verbatim quote]
**New Loopholes Found**: [if any]

### Recommended Skill Hardening

[Specific additions to address rationalizations found]
```

## Priority Order

Test high-risk disciplines first:

1. Delegation Discipline (Tests 1.1-1.3) - Most frequently violated
2. Viewport Reset Rule (Tests 6.1-6.2) - Subtle, easy to miss
3. Conditional Routing (Tests 3.1-3.2) - Cost optimization depends on this
4. Code Review Compliance (Tests 4.1-4.2) - User pressure risk
5. Communication Policy (Tests 2.1-2.2) - Less severe but impacts UX
6. Phase Gate Enforcement (Test 5.1) - Depends on task context
7. Error Routing (Tests 7.1-7.2) - Lower risk overall
